{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# CH14 ë”¥ëŸ¬ë‹ (Keras / TensorFlow)\n\nì—…ë¡œë“œëœ **CH14 ë”¥ëŸ¬ë‹.ppt** ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ,  \në”¥ëŸ¬ë‹ ê°œìš”/ì ˆì°¨, **ì´ì§„ ë¶„ë¥˜(ë‹¹ë‡¨ë³‘)**, **ë‹¤ì¤‘ ë¶„ë¥˜(ë¶“ê½ƒ)**, **íšŒê·€(ë³´ìŠ¤í„´ ì£¼íƒ)**, ê·¸ë¦¬ê³  **[í”ŒëŸ¬ìŠ¤ ì˜ˆì œ] ë‹¹ë‡¨ë³‘ ì§„í–‰ë„ ì˜ˆì¸¡(ê°œë…/ëŒ€ì²´ ì‹¤ìŠµ)** íë¦„ì„  \nğŸ‘‰ **ì„¤ëª… + ì‹¤ìŠµ ì˜ˆì œ**ë¡œ êµ¬ì„±í•œ ë…¸íŠ¸ë¶ì…ë‹ˆë‹¤. îˆ€fileciteîˆ‚turn8file2îˆ\n\n> âš ï¸ ì‹¤í–‰ í™˜ê²½ì— ë”°ë¼ `tensorflow`ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n> ì„¤ì¹˜ê°€ í•„ìš”í•˜ë©´: `pip install tensorflow` (í™˜ê²½ ì •ì±…ì— ë”°ë¼ ì œí•œë  ìˆ˜ ìˆìŒ)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 14.1 ë”¥ëŸ¬ë‹ì˜ ê°œìš”\n- ì‹ ê²½ë§(neural network): ì…ë ¥â†’ê°€ì¤‘ì¹˜/í•©â†’í™œì„±í™”â†’ì¶œë ¥\n- ì…ë ¥ì¸µ/ì€ë‹‰ì¸µ/ì¶œë ¥ì¸µ, ì¸µì´ ê¹Šì–´ì§€ë©´(deep) ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ\n- ì ˆì°¨: ë°ì´í„° ì¤€ë¹„ â†’ ì „ì²˜ë¦¬(ê²°ì¸¡/ìŠ¤ì¼€ì¼ë§) â†’ ëª¨ë¸ ì •ì˜ â†’ ì»´íŒŒì¼(optimizer/loss/metric) â†’ í•™ìŠµ(fit) â†’ í‰ê°€(evaluate) â†’ í•™ìŠµ ê³¡ì„  ì‹œê°í™” îˆ€fileciteîˆ‚turn8file2îˆ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# (ê¶Œì¥) ë”¥ëŸ¬ë‹ ì˜ˆì œëŠ” tensorflow.kerasë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\ntry:\n    import tensorflow as tf\n    from tensorflow.keras import Sequential\n    from tensorflow.keras.layers import Dense\n    print(\"TensorFlow version:\", tf.__version__)\nexcept Exception as e:\n    print(\"TensorFlow import ì‹¤íŒ¨:\", e)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 14.2 ë”¥ëŸ¬ë‹ ë¶„ë¥˜: ë‹¹ë‡¨ë³‘ ë°œë³‘ ì˜ˆì¸¡(ì´ì§„ ë¶„ë¥˜)\nPPTì—ì„œëŠ” Kaggle Pima Indians ë°ì´í„°(`diabetes.csv`)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. îˆ€fileciteîˆ‚turn8file2îˆ\n\nì—¬ê¸°ì„œëŠ” **íŒŒì¼ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©**, ì—†ìœ¼ë©´ **êµ¬ì¡°ë¥¼ ì—°ìŠµí•  ìƒ˜í”Œ ë°ì´í„°**ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\n\ncsv_name = \"diabetes.csv\"  # íŒŒì¼ì´ ìˆìœ¼ë©´ ìë™ ì‚¬ìš©\n\nif os.path.exists(csv_name):\n    df = pd.read_csv(csv_name)\n    print(\"loaded:\", df.shape)\nelse:\n    # ìƒ˜í”Œ ë°ì´í„°(í•™ìŠµìš©)\n    rng = np.random.default_rng(42)\n    n = 600\n    df = pd.DataFrame({\n        \"Pregnancies\": rng.integers(0, 10, n),\n        \"Glucose\": rng.normal(120, 25, n).clip(0),\n        \"BloodPressure\": rng.normal(70, 12, n).clip(0),\n        \"SkinThickness\": rng.normal(20, 8, n).clip(0),\n        \"Insulin\": rng.normal(80, 35, n).clip(0),\n        \"BMI\": rng.normal(30, 6, n).clip(0),\n        \"DiabetesPedigreeFunction\": rng.normal(0.5, 0.2, n).clip(0),\n        \"Age\": rng.integers(21, 70, n)\n    })\n    # Outcome ìƒì„±(ëŒ€ëµì )\n    logit = (df[\"Glucose\"]*0.02 + df[\"BMI\"]*0.08 + df[\"Age\"]*0.01 - 8.0)\n    prob = 1/(1+np.exp(-logit))\n    df[\"Outcome\"] = (rng.random(n) < prob).astype(int)\n    print(\"sample:\", df.shape)\n\ndf.head()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### (1) ì „ì²˜ë¦¬: 0ì´ ë  ìˆ˜ ì—†ëŠ” ì—´ì„ NaNìœ¼ë¡œ ë°”ê¾¸ê³  dropna (PPT íë¦„) îˆ€fileciteîˆ‚turn8file2îˆ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "df2 = df.copy()\ncolumns = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\nfor c in columns:\n    df2[c] = df2[c].replace(0, np.nan)\n\ndf2 = df2.dropna()\ndf2.shape\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### (2) íŠ¹ì„±/íƒ€ê¹ƒ ë¶„ë¦¬ + ìŠ¤ì¼€ì¼ë§ + train/test split îˆ€fileciteîˆ‚turn8file2îˆ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "target = df2.pop(\"Outcome\").values\nX = df2.values\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, target, test_size=0.2, random_state=42, stratify=target\n)\n\nscaler = StandardScaler()\nX_train_s = scaler.fit_transform(X_train)\nX_test_s = scaler.transform(X_test)\n\nX_train_s.shape, X_test_s.shape\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### (3) ëª¨ë¸ ì •ì˜/ì»´íŒŒì¼/í•™ìŠµ\n- ì€ë‹‰ì¸µ: relu\n- ì´ì§„ ë¶„ë¥˜ ì¶œë ¥ì¸µ: sigmoid\n- loss: binary_crossentropy\n- optimizer: Adam\n- metric: accuracy îˆ€fileciteîˆ‚turn8file2îˆ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# tensorflowê°€ ì—†ëŠ” í™˜ê²½ì´ë©´ ì´ ì…€ì€ ì‹¤í–‰ë˜ì§€ ì•Šì„ ìˆ˜ ìˆì–´ìš”.\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential([\n    Dense(12, activation=\"relu\", input_dim=X_train_s.shape[1]),\n    Dense(8, activation=\"relu\"),\n    Dense(1, activation=\"sigmoid\")\n])\n\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nhistory = model.fit(\n    X_train_s, y_train,\n    validation_split=0.2,\n    epochs=30,\n    batch_size=32,\n    verbose=0\n)\n\nloss, acc = model.evaluate(X_test_s, y_test, verbose=0)\nprint(\"test loss:\", loss, \"test acc:\", acc)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### (4) í•™ìŠµ ê³¡ì„  ì‹œê°í™”: loss/accuracy îˆ€fileciteîˆ‚turn8file2îˆ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "hist = history.history\nplt.plot(hist[\"loss\"], label=\"loss\")\nplt.plot(hist[\"val_loss\"], label=\"val_loss\")\nplt.legend()\nplt.title(\"Loss\")\nplt.show()\n\nplt.plot(hist[\"accuracy\"], label=\"acc\")\nplt.plot(hist[\"val_accuracy\"], label=\"val_acc\")\nplt.legend()\nplt.title(\"Accuracy\")\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 14.2 LAB) ë”¥ëŸ¬ë‹ìœ¼ë¡œ ë¶“ê½ƒ í’ˆì¢… ë¶„ë¥˜(ë‹¤ì¤‘ ë¶„ë¥˜)\n- ì¶œë ¥ì¸µ: softmax\n- loss: sparse_categorical_crossentropy\nPPTì˜ LAB íë¦„ì„ sklearn iris ë°ì´í„°ë¡œ ì¬í˜„í•©ë‹ˆë‹¤. îˆ€fileciteîˆ‚turn8file2îˆ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nmodel2 = Sequential([\n    Dense(16, activation=\"relu\", input_dim=X_train.shape[1]),\n    Dense(16, activation=\"relu\"),\n    Dense(3, activation=\"softmax\")  # 3-class\n])\n\nmodel2.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\nh2 = model2.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=16, verbose=0)\n\nloss, acc = model2.evaluate(X_test, y_test, verbose=0)\nprint(\"test acc:\", acc)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 14.3 ë”¥ëŸ¬ë‹ íšŒê·€: (ëŒ€ì²´ ì‹¤ìŠµ) ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²©\nPPTëŠ” ë³´ìŠ¤í„´ ì£¼íƒì„ ì˜ˆë¡œ ë“¤ì§€ë§Œ, ìµœì‹  í™˜ê²½ì—ì„œëŠ” ë³´ìŠ¤í„´ ë°ì´í„° ë¡œë”©ì´ ì œí•œë˜ëŠ” ê²½ìš°ê°€ ìˆì–´\n**ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ**ìœ¼ë¡œ ë™ì¼í•œ íšŒê·€ íë¦„(ìŠ¤ì¼€ì¼ë§â†’Denseâ†’mse/mae)ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤. îˆ€fileciteîˆ‚turn8file2îˆ"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nhousing = fetch_california_housing()\nX = housing.data\ny = housing.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\nreg = Sequential([\n    Dense(64, activation=\"relu\", input_dim=X_train.shape[1]),\n    Dense(64, activation=\"relu\"),\n    Dense(1)  # íšŒê·€ëŠ” í™œì„±í™” í•¨ìˆ˜ ì—†ìŒ(ê¸°ë³¸ ì„ í˜•)\n])\n\nreg.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\nh3 = reg.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=32, verbose=0)\n\nloss, mae = reg.evaluate(X_test, y_test, verbose=0)\nprint(\"test MSE:\", loss, \"test MAE:\", mae)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 14.4 [í”ŒëŸ¬ìŠ¤ ì˜ˆì œ] ë‹¹ë‡¨ë³‘ ì§„í–‰ë„ ì˜ˆì¸¡\nPPTì—ëŠ” ë‹¹ë‡¨ë³‘ ì§„í–‰ë„ ì˜ˆì¸¡ ì˜ˆì œê°€ í¬í•¨ë©ë‹ˆë‹¤. îˆ€fileciteîˆ‚turn8file2îˆ\n\nì—¬ê¸°ì„œëŠ” ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ **sklearn diabetes(íšŒê·€)** ë°ì´í„°ë¡œ\në”¥ëŸ¬ë‹ íšŒê·€ ëª¨ë¸ì„ ë§Œë“¤ì–´ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´ ì‹¤ìŠµí•©ë‹ˆë‹¤."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\ndiab = load_diabetes()\nX = diab.data\ny = diab.target  # ì§„í–‰ë„(ì—°ì†ê°’)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\ndl = Sequential([\n    Dense(64, activation=\"relu\", input_dim=X_train.shape[1]),\n    Dense(32, activation=\"relu\"),\n    Dense(1)\n])\n\ndl.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\nh4 = dl.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=0)\n\nloss, mae = dl.evaluate(X_test, y_test, verbose=0)\nprint(\"test MSE:\", loss, \"test MAE:\", mae)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ì •ë¦¬ ì²´í¬ë¦¬ìŠ¤íŠ¸\n- [ ] ë”¥ëŸ¬ë‹(ì‹ ê²½ë§) êµ¬ì¡°ì™€ ì ˆì°¨ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤.\n- [ ] ì´ì§„ ë¶„ë¥˜ì—ì„œ sigmoid + binary_crossentropyë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n- [ ] ë‹¤ì¤‘ ë¶„ë¥˜ì—ì„œ softmax + (sparse_)categorical_crossentropyë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n- [ ] íšŒê·€ì—ì„œ mse/maeë¥¼ ì´ìš©í•´ í•™ìŠµ/í‰ê°€í•  ìˆ˜ ìˆë‹¤.\n- [ ] í•™ìŠµ ê³¡ì„ (loss/accuracy)ì„ í•´ì„í•  ìˆ˜ ìˆë‹¤.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}